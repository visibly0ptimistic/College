{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897b9543-4275-417c-8f35-879379f897e9",
   "metadata": {},
   "source": [
    "# M6 Project\n",
    "\n",
    "In this project you will compare the performance of LDA and SVM for face recognition. You will use the Olivetti faces dataset, which contains 400 64x64 images from 40 different subjects, and your task is to discover the identity of a given face image. Some of these images are illustrated below.\n",
    "\n",
    "<img src=\"m6project.png\" width=\"400\"/>\n",
    "\n",
    "An initial version of the code with the problem specification (below) and a report template are available (at the bottom). Deliverables are the final code (non-functioning code is worth 0 points) and the comparison report.\n",
    "\n",
    "Solve the task above using:\n",
    "- LDA (20pts)\n",
    "- SVM (20pts)\n",
    "\n",
    "For LDA:\n",
    "- Visualize a 2D representation of the faces in the dataset (20pts)\n",
    "\n",
    "Split the dataset so that the first 5 images per subject are used for training, and the last 5 images are used for testing. If you need a validation set, use part of your training data. Compare the performance of LDA and SVM in terms of:\n",
    "- Average F-Score (15pts)\n",
    "- Confusion matrix (15pts)\n",
    "- Visualize the individuals with highest confusion and check if they look alike (10pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234bcfb-d702-43e8-a922-26b790557075",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "You are free to change the code below as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881f577-3977-4914-ab97-3814209e3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b20176-5987-43f3-b2d0-f0e4aac9c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "\n",
    "faces = fetch_olivetti_faces()\n",
    "\n",
    "_, img_height, img_width = faces.images.shape\n",
    "\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3639fc-5c7a-45dd-95bd-6a8f6d1fce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "\n",
    "N_IDENTITIES = len(np.unique(faces.target)) # how many different individuals are in the dataset\n",
    "GALLERY_SIZE = 5                            # use the first GALLERY_SIZE images per individual for training, the rest for testing\n",
    "\n",
    "gallery_indices = []\n",
    "probe_indices = []\n",
    "for i in range(N_IDENTITIES):\n",
    "    indices = list(np.where(faces.target == i)[0])\n",
    "    gallery_indices += indices[:GALLERY_SIZE]\n",
    "    probe_indices += indices[GALLERY_SIZE:]\n",
    "\n",
    "x_train = faces.images[gallery_indices].reshape(-1, img_height*img_width) # vectorize train images\n",
    "y_train = faces.target[gallery_indices]\n",
    "x_test = faces.images[probe_indices].reshape(-1, img_height*img_width)    # vectorize test images\n",
    "y_test = faces.target[probe_indices]\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879df5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the LDA and SVM models then visualizing 2D LDA\n",
    "\n",
    "lda = LDA(n_components=2)\n",
    "x_train_lda = lda.fit_transform(x_train, y_train)\n",
    "x_test_lda = lda.transform(x_test)\n",
    "\n",
    "lda_clf = svm.SVC(kernel='linear')\n",
    "lda_clf.fit(x_train_lda, y_train)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(N_IDENTITIES):\n",
    "    plt.scatter(x_train_lda[y_train==i, 0], x_train_lda[y_train==i, 1], label=str(i))\n",
    "plt.legend(loc='best')\n",
    "plt.title('LDA 2D representation')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# evaluating the performance of the models\n",
    "\n",
    "y_pred_lda = lda_clf.predict(x_test_lda)\n",
    "f_score_lda = f1_score(y_test, y_pred_lda, average='macro')\n",
    "cm_lda = confusion_matrix(y_test, y_pred_lda)\n",
    "\n",
    "y_pred_svm = clf.predict(x_test)\n",
    "f_score_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "print(\"LDA F-Score: \", f_score_lda)\n",
    "print(\"SVM F-Score: \", f_score_svm)\n",
    "\n",
    "print(\"LDA Confusion Matrix: \\n\", cm_lda)\n",
    "print(\"SVM Confusion Matrix: \\n\", cm_svm)\n",
    "\n",
    "\n",
    "\n",
    "# visualizing the individuals with the highest confusion\n",
    "\n",
    "def plot_most_confused_individuals(cm, num):\n",
    "    np.fill_diagonal(cm, 0)\n",
    "    \n",
    "    confused_ids = np.argsort(-cm.flatten())[:num]\n",
    "    individuals = []\n",
    "    for id in confused_ids:\n",
    "        i, j = divmod(id, cm.shape[0])\n",
    "        individuals.append((i, j))\n",
    "\n",
    "    fig, axes = plt.subplots(1, num, figsize=(10, 10))\n",
    "    for (i, j), ax in zip(individuals, axes):\n",
    "        ax.imshow(faces.images[faces.target == j][0], cmap='gray')\n",
    "        ax.set_title(f'Predicted: {j}, Actual: {i}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "plot_most_confused_individuals(cm_lda, 5)  # For LDA\n",
    "plot_most_confused_individuals(cm_svm, 5)  # For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf327e-543f-4b96-941f-047778ef2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize image sets\n",
    "def show_images(imgs, num_rows, num_cols):\n",
    "    assert len(imgs) == num_rows*num_cols\n",
    "\n",
    "    full = None\n",
    "    for i in range(num_rows):\n",
    "        row = None\n",
    "        for j in range(num_cols):\n",
    "            if row is None:\n",
    "                row = imgs[i*num_cols+j].reshape(img_height, img_width)*255.0\n",
    "            else:\n",
    "                row = np.concatenate((row, imgs[i*num_cols+j].reshape(img_height, img_width)*255.0), axis=1)\n",
    "        if full is None:\n",
    "            full = row\n",
    "        else:\n",
    "            full = np.concatenate((full, row), axis=0)\n",
    "\n",
    "    f = plt.figure(figsize=(num_cols, num_rows))\n",
    "    plt.imshow(full, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print('TRAINING')\n",
    "show_images(x_train, N_IDENTITIES, GALLERY_SIZE)\n",
    "print('TESTING')\n",
    "show_images(x_test, N_IDENTITIES, 10 - GALLERY_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24fba25-a31f-4e09-a29d-e26f2fb624b9",
   "metadata": {},
   "source": [
    "# Report template\n",
    "\n",
    "## Visualization of the 2D face representation computed by LDA\n",
    "\n",
    "I began the investigation by transforming the multi-dimensional facial recognition dataset into a 2D dataset using Linear Discriminant Analysis (LDA). This technique allowed me to reduce the dimensionality of the data while preserving as much of the original variance as possible. Consequently, I could visually represent the data and see how different individuals are grouped together.\n",
    "\n",
    "\n",
    "## Experimental results\n",
    "\n",
    "In the experiment, I utilized two different classifiers, the Linear Discriminant Analysis (LDA) and the Support Vector Machine (SVM) to predict identities based on the face recognition data. I then measured the performance of these two models using the F-score metric.\n",
    "\n",
    "The F-score for the LDA classifier was 0.373, indicating a fair but not exceptional performance in recognizing faces. The LDA may have struggled due to the reduction of dimensions and the resulting loss of data complexity.\n",
    "\n",
    "On the other hand, the SVM classifier showed an F-score of 0.9, significantly outperforming the LDA model. This suggests that the SVM was more effective in recognizing and differentiating individuals, even in the high-dimensional space.\n",
    "\n",
    "The confusion matrices for both the LDA and SVM models further highlights the difference in their performance. The LDA matrix showed several misclassifications, indicating confusion between different individuals. In contrast, the SVM confusion matrix had more values along the diagonal and fewer misclassifications, reaffirming its superior performance in this instance.\n",
    "\n",
    "\n",
    "## Analysis of the Results\n",
    "\n",
    "While both LDA and SVM are powerful tools for face recognition, the experiment demonstrated that SVM had a distinct advantage over LDA in this particular task. The probable reason is that SVM works effectively with high dimensional data and finds the optimal plane that maximizes the margin between different classes. In contrast, LDA's performance may have been affected by the reduction in dimensions, causing it to lose some information crucial for accurately classifying faces.\n",
    "\n",
    "\n",
    "## Visualization of the Individuals with Highest Confusion\n",
    "\n",
    "Finally, I visualized the instances where the models had the most confusion, the individuals who were most frequently misclassified. These instances can provide useful insights into why these models may have made errors and help us refine our models in future iterations. We should look into these instances carefully to identify any common traits or anomalies that could have led to the misclassifications.\n",
    "\n",
    "In conclusion, while LDA is a valuable tool for visualizing high-dimensional data, our experiment suggests that SVM might be a better choice for face recognition tasks given its superior performance in our tests. Further testing could help to confirm these findings and improve these models performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
